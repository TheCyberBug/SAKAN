{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastkan import FastKAN as KAN\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchtext\n",
    "torchtext.disable_torchtext_deprecation_warning()\n",
    "\n",
    "from torchtext.datasets import IMDB\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kaloq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kaloq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kaloq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./imdb.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:00<00:00, 860592.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  label\n",
       "0  One of the other reviewers has mentioned that ...  positive      1\n",
       "1  A wonderful little production. <br /><br />The...  positive      1\n",
       "2  I thought this was a wonderful way to spend ti...  positive      1\n",
       "3  Basically there's a family where a little boy ...  negative      0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_label(label):\n",
    "    return 1 if label == 'positive' else 0\n",
    "\n",
    "data['label'] = data['sentiment'].progress_apply(transform_label)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:00<00:00, 105655.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  label  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive      1   \n",
       "1  A wonderful little production. <br /><br />The...  positive      1   \n",
       "2  I thought this was a wonderful way to spend ti...  positive      1   \n",
       "3  Basically there's a family where a little boy ...  negative      0   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive      1   \n",
       "\n",
       "   token_length  \n",
       "0           307  \n",
       "1           162  \n",
       "2           166  \n",
       "3           138  \n",
       "4           230  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['token_length'] = data.review.progress_apply(lambda x: len(x.split()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       232.849320\n",
       "std        177.497046\n",
       "min         10.000000\n",
       "25%        125.000000\n",
       "50%        172.000000\n",
       "75%        284.000000\n",
       "max       2470.000000\n",
       "Name: token_length, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pos = data[data['label'] == 1]\n",
    "data_pos['token_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       229.464560\n",
       "std        164.947795\n",
       "min          4.000000\n",
       "25%        128.000000\n",
       "50%        174.000000\n",
       "75%        278.000000\n",
       "max       1522.000000\n",
       "Name: token_length, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_neg = data[data['label'] == 0]\n",
    "data_neg['token_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    # \n",
    "    words = word_tokenize(text)\n",
    "    sent = [word for word in words if word not in stop_words]\n",
    "    sent = ' '.join(sent)\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:23<00:00, 2110.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>token_length</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  label  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive      1   \n",
       "1  A wonderful little production. <br /><br />The...  positive      1   \n",
       "2  I thought this was a wonderful way to spend ti...  positive      1   \n",
       "3  Basically there's a family where a little boy ...  negative      0   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive      1   \n",
       "\n",
       "   token_length                                              clean  \n",
       "0           307  one reviewers mentioned watching 1 oz episode ...  \n",
       "1           162  wonderful little production filming technique ...  \n",
       "2           166  thought wonderful way spend time hot summer we...  \n",
       "3           138  basically theres family little boy jake thinks...  \n",
       "4           230  petter matteis love time money visually stunni...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the preprocessing to the 'review' column (assuming the column name is 'review')\n",
    "data['clean'] = data.review.progress_apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows of the dataframe with the cleaned reviews\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:32<00:00, 1559.37it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "max_l = 250\n",
    "data['tokenized'] = data.clean.progress_apply(lambda x: tokenizer.encode(text=x, add_special_tokens=False, truncation=True, add_prefix_space=True, padding='max_length', max_length=max_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   review sentiment  label  \\\n",
       "0      One of the other reviewers has mentioned that ...  positive      1   \n",
       "1      A wonderful little production. <br /><br />The...  positive      1   \n",
       "2      I thought this was a wonderful way to spend ti...  positive      1   \n",
       "3      Basically there's a family where a little boy ...  negative      0   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive      1   \n",
       "...                                                  ...       ...    ...   \n",
       "49995  I thought this movie did a down right good job...  positive      1   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative      0   \n",
       "49997  I am a Catholic taught in parochial elementary...  negative      0   \n",
       "49998  I'm going to have to disagree with the previou...  negative      0   \n",
       "49999  No one expects the Star Trek movies to be high...  negative      0   \n",
       "\n",
       "       token_length                                              clean  \\\n",
       "0               307  one reviewers mentioned watching 1 oz episode ...   \n",
       "1               162  wonderful little production filming technique ...   \n",
       "2               166  thought wonderful way spend time hot summer we...   \n",
       "3               138  basically theres family little boy jake thinks...   \n",
       "4               230  petter matteis love time money visually stunni...   \n",
       "...             ...                                                ...   \n",
       "49995           194  thought movie right good job wasnt creative or...   \n",
       "49996           112  bad plot bad dialogue bad acting idiotic direc...   \n",
       "49997           230  catholic taught parochial elementary schools n...   \n",
       "49998           212  im going disagree previous comment side maltin...   \n",
       "49999           129  one expects star trek movies high art fans exp...   \n",
       "\n",
       "                                               tokenized  \n",
       "0      [530, 30702, 4750, 4964, 352, 15649, 4471, 345...  \n",
       "1      [7932, 1310, 3227, 17691, 8173, 555, 32935, 14...  \n",
       "2      [1807, 7932, 835, 4341, 640, 3024, 3931, 5041,...  \n",
       "3      [6209, 262, 411, 1641, 1310, 2933, 474, 539, 6...  \n",
       "4      [4273, 353, 36908, 271, 1842, 640, 1637, 22632...  \n",
       "...                                                  ...  \n",
       "49995  [1807, 3807, 826, 922, 1693, 373, 429, 7325, 2...  \n",
       "49996  [2089, 7110, 2089, 10721, 2089, 7205, 4686, 16...  \n",
       "49997  [32171, 4160, 7817, 1582, 5374, 498, 19823, 42...  \n",
       "49998  [545, 1016, 12546, 2180, 2912, 1735, 26868, 25...  \n",
       "49999  [530, 13423, 3491, 30784, 6918, 1029, 1242, 32...  \n",
       "\n",
       "[50000 rows x 6 columns]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:00<00:00, 1348512.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    25000.0\n",
       "mean       250.0\n",
       "std          0.0\n",
       "min        250.0\n",
       "25%        250.0\n",
       "50%        250.0\n",
       "75%        250.0\n",
       "max        250.0\n",
       "Name: ct_length, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ct_length'] = data.tokenized.progress_apply(lambda x: len(x))\n",
    "data_pos = data[data['label'] == 1]\n",
    "data_pos['ct_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X = data.tokenized\n",
    "y = data.label\n",
    "\n",
    "# Use train_test_split to split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=39)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.tolist()).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.tolist()).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.tolist()).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.tolist()).to(device)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentCNNModel(\n",
       "  (embedding): Embedding(50257, 128)\n",
       "  (conv1): Conv2d(1, 100, kernel_size=(1, 128), stride=(1, 1))\n",
       "  (conv2): Conv2d(1, 100, kernel_size=(3, 128), stride=(1, 1), padding=(1, 0))\n",
       "  (conv3): Conv2d(1, 100, kernel_size=(5, 128), stride=(1, 1), padding=(2, 0))\n",
       "  (dropout): Dropout(p=0.35, inplace=False)\n",
       "  (kan): FastKAN(\n",
       "    (layers): ModuleList(\n",
       "      (0): FastKANLayer(\n",
       "        (layernorm): LayerNorm((37500,), eps=1e-05, elementwise_affine=True)\n",
       "        (rbf): RadialBasisFunction()\n",
       "        (spline_linear): SplineLinear(in_features=300000, out_features=512, bias=False)\n",
       "        (base_linear): Linear(in_features=37500, out_features=512, bias=True)\n",
       "      )\n",
       "      (1): FastKANLayer(\n",
       "        (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (rbf): RadialBasisFunction()\n",
       "        (spline_linear): SplineLinear(in_features=4096, out_features=128, bias=False)\n",
       "        (base_linear): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (2): FastKANLayer(\n",
       "        (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (rbf): RadialBasisFunction()\n",
       "        (spline_linear): SplineLinear(in_features=1024, out_features=2, bias=False)\n",
       "        (base_linear): Linear(in_features=128, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastkan import FastKAN as KAN\n",
    "\n",
    "class SentimentCNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(SentimentCNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.conv1 = nn.Conv2d(1, 100, (1, embed_dim), padding=(0, 0))  # 1-gram\n",
    "        self.conv2 = nn.Conv2d(1, 100, (3, embed_dim), padding=(1, 0))  # 3-gram\n",
    "        self.conv3 = nn.Conv2d(1, 100, (5, embed_dim), padding=(2, 0))  # 5-gram\n",
    "        self.dropout = nn.Dropout(0.35)\n",
    "        # Replace dense layers with FastKAN\n",
    "        self.kan = KAN([37500, 512, 128, num_class])\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text).unsqueeze(1)  # Add channel dimension\n",
    "        \n",
    "        conv1_out = F.relu(self.conv1(embedded)).squeeze(3)\n",
    "        conv2_out = F.relu(self.conv2(embedded)).squeeze(3)\n",
    "        conv3_out = F.relu(self.conv3(embedded)).squeeze(3)\n",
    "        \n",
    "        pooled1 = F.max_pool1d(conv1_out, 2).squeeze(2)\n",
    "        pooled2 = F.max_pool1d(conv2_out, 2).squeeze(2)\n",
    "        pooled3 = F.max_pool1d(conv3_out, 2).squeeze(2)\n",
    "\n",
    "        \n",
    "        cat = torch.cat((pooled1, pooled2, pooled3), 1)\n",
    "        cat = self.dropout(cat)\n",
    "        \n",
    "        cat = cat.view(cat.size(0), -1)\n",
    "        # Use FastKAN for final classification\n",
    "        out = self.kan(cat)\n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "vocab_size = len(tokenizer)  # Vocabulary size of GPT-2 tokenizer\n",
    "embed_dim = 128  # Embedding dimension\n",
    "num_class = 2  # Number of classes (negative, positive)\n",
    "\n",
    "model = SentimentCNNModel(vocab_size, embed_dim, num_class)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 625/625 [00:35<00:00, 17.48it/s, accuracy=0.537, loss=0.0181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.161401811313629, Accuracy: 0.537275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 625/625 [00:36<00:00, 17.08it/s, accuracy=0.774, loss=0.00738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.47252855350971223, Accuracy: 0.774175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 625/625 [00:38<00:00, 16.45it/s, accuracy=0.879, loss=0.00447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.28603353217840194, Accuracy: 0.8787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 625/625 [00:37<00:00, 16.81it/s, accuracy=0.925, loss=0.00287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.18366781608462335, Accuracy: 0.924975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 625/625 [00:35<00:00, 17.43it/s, accuracy=0.952, loss=0.00192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.12297664624005557, Accuracy: 0.9522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 625/625 [00:35<00:00, 17.45it/s, accuracy=0.968, loss=0.0013] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.08310348702147603, Accuracy: 0.9675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 625/625 [00:36<00:00, 17.36it/s, accuracy=0.98, loss=0.000817] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.05228792381752283, Accuracy: 0.9803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 625/625 [00:35<00:00, 17.44it/s, accuracy=0.985, loss=0.000627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.04015079543367028, Accuracy: 0.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 625/625 [00:35<00:00, 17.40it/s, accuracy=0.991, loss=0.000412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.02639798095920123, Accuracy: 0.990825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 625/625 [00:35<00:00, 17.42it/s, accuracy=0.993, loss=0.00033] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.021127590995328502, Accuracy: 0.9928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 625/625 [00:35<00:00, 17.42it/s, accuracy=0.995, loss=0.000242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.015494658929202706, Accuracy: 0.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 625/625 [00:35<00:00, 17.42it/s, accuracy=0.995, loss=0.000208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.01330933862022357, Accuracy: 0.9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 625/625 [00:36<00:00, 17.31it/s, accuracy=0.997, loss=0.000167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.010704210755182431, Accuracy: 0.99655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 625/625 [00:35<00:00, 17.43it/s, accuracy=0.997, loss=0.000132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.00843191039004596, Accuracy: 0.997025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 625/625 [00:35<00:00, 17.41it/s, accuracy=0.998, loss=0.000104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.006642530341190286, Accuracy: 0.997775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 625/625 [00:35<00:00, 17.41it/s, accuracy=0.998, loss=9.62e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.0061551289284077935, Accuracy: 0.9977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 625/625 [00:35<00:00, 17.41it/s, accuracy=0.998, loss=7.39e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.004730923702463042, Accuracy: 0.998375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 625/625 [00:34<00:00, 18.00it/s, accuracy=0.998, loss=7.54e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.00482643639507587, Accuracy: 0.998325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 625/625 [00:35<00:00, 17.58it/s, accuracy=0.999, loss=5.62e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.0035974783867248335, Accuracy: 0.99865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 625/625 [00:35<00:00, 17.41it/s, accuracy=0.999, loss=5.77e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.0036914174732752144, Accuracy: 0.99875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# Define learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "\n",
    "# Define the accuracy calculation\n",
    "def calculate_accuracy(preds, labels):\n",
    "    _, predicted = torch.max(preds, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct\n",
    "\n",
    "# Training loop with loss and accuracy display\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
    "        for texts, labels in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            correct_predictions += calculate_accuracy(outputs, labels)\n",
    "            total_predictions += labels.size(0)\n",
    "            \n",
    "            accuracy = correct_predictions / total_predictions\n",
    "            \n",
    "            pbar.set_postfix(loss=total_loss/total_predictions, accuracy=accuracy)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.851, Test Loss: 0.014452516278624535\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in test_loader:\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            correct += calculate_accuracy(outputs, labels)\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    avg_loss = total_loss / total\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, avg_loss = evaluate(model, test_loader)\n",
    "print(f'Test Accuracy: {accuracy}, Test Loss: {avg_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}